/**
 * Provider Comparison — Cost/Quality Analyzer
 *
 * Analyzes and compares costs and quality metrics across Mock, Local LLM, and Claude Haiku providers.
 * This is the second critical piece for matrix validation—evaluating whether Claude API is worth
 * the cost compared to free alternatives.
 *
 * Exports:
 *   - ProviderType: Union of provider identifiers
 *   - ComparisonMetrics: Raw metrics from a provider run
 *   - ComparisonResult: Final scored/recommended result
 *   - ProviderComparator: Main class for analysis
 */

export type ProviderType = "mock" | "local" | "anthropic";

/**
 * Raw metrics collected from a single provider run.
 * These represent the actual cost and quality signals.
 */
export interface ComparisonMetrics {
	inputTokens: number;           // Tokens sent to provider
	outputTokens: number;          // Tokens generated by provider
	estimatedCost: number;         // USD cost for this run
	responseTime: number;          // Time in milliseconds
	workPatternsCount: number;     // Number of work patterns identified
	focusScore: number;            // Focus/concentration score (0-1)
	connectionsCount: number;      // Cross-source connections found
}

/**
 * Final scored and recommended result for a provider.
 * Combines metrics with quality and privacy assessments.
 */
export interface ComparisonResult {
	provider: ProviderType;
	metrics: ComparisonMetrics;
	qualityScore: number;          // 0-1: Overall output quality
	privacyScore: number;          // 0-1: Privacy compliance for tier
	consistency: number;           // 0-1: Consistency vs mock baseline
	recommendation: string;        // Human-readable recommendation
}

/**
 * ProviderComparator — Analyzes and scores provider outputs
 *
 * Core responsibilities:
 * - Calculate cost based on token usage and provider pricing
 * - Score quality based on output characteristics
 * - Compare consistency against baseline (mock)
 * - Generate actionable recommendations
 */
export class ProviderComparator {
	constructor(private readonly provider: ProviderType) {}

	/**
	 * Calculate USD cost for a provider run.
	 *
	 * Pricing (Claude Haiku):
	 *   - Input: $0.80 per 1M tokens
	 *   - Output: $0.40 per 1M tokens
	 *
	 * Mock and Local providers have zero cost.
	 */
	calculateCost(inputTokens: number, outputTokens: number): number {
		if (this.provider === "mock" || this.provider === "local") {
			return 0;
		}

		// Claude Haiku pricing
		const INPUT_COST_PER_MILLION = 0.8;
		const OUTPUT_COST_PER_MILLION = 0.4;

		const inputCost = (inputTokens * INPUT_COST_PER_MILLION) / 1_000_000;
		const outputCost = (outputTokens * OUTPUT_COST_PER_MILLION) / 1_000_000;

		return inputCost + outputCost;
	}

	/**
	 * Score output quality on a 0-1 scale.
	 *
	 * Scoring breakdown (max 1.0):
	 *   - Base: 0.5
	 *   - Headline quality: 0.2 max
	 *     - 20-150 chars: 0.2
	 *     - 10-19 chars: 0.1
	 *     - <10 chars: 0.0
	 *   - Work patterns: 0.3 max
	 *     - 2+ patterns: 0.3
	 *     - 1 pattern: 0.15
	 *     - 0 patterns: 0.0
	 *   - Cross-source connections: 0.2 max
	 *     - 2+ connections: 0.2
	 *     - 1 connection: 0.1
	 *     - 0 connections: 0.0
	 *   - Focus score accuracy: 0.2 max
	 *     - Reasonable for persona: 0.2
	 *     - Partially reasonable: 0.1
	 *     - Unreasonable: 0.0
	 *
	 * Total is capped at 1.0.
	 */
	scoreQuality(output: Record<string, unknown>, persona: string): number {
		let score = 0.5; // base

		// ── Headline Quality ────────────────────────────────────────
		const headline = output.headline as string | undefined;
		if (headline) {
			const len = headline.length;
			if (len >= 20 && len <= 150) {
				score += 0.2;
			} else if (len >= 10 && len < 20) {
				score += 0.1;
			}
			// else: <10 chars = no points
		}

		// ── Work Patterns Count ─────────────────────────────────────
		const workPatterns = output.work_patterns as string[] | undefined;
		const patternsCount = workPatterns?.length ?? 0;
		if (patternsCount >= 2) {
			score += 0.3;
		} else if (patternsCount === 1) {
			score += 0.15;
		}

		// ── Cross-Source Connections ────────────────────────────────
		const connections = output.cross_source_connections as
			| string[]
			| undefined;
		const connectionsCount = connections?.length ?? 0;
		if (connectionsCount >= 2) {
			score += 0.2;
		} else if (connectionsCount === 1) {
			score += 0.1;
		}

		// ── Focus Score Accuracy ────────────────────────────────────
		const focusScore = output.focus_score as number | undefined;
		if (focusScore !== undefined) {
			const reasonableness = this.assessFocusScoreReasonableness(
				focusScore,
				persona
			);
			if (reasonableness === "reasonable") {
				score += 0.2;
			} else if (reasonableness === "partial") {
				score += 0.1;
			}
			// else: unreasonable = no points
		}

		// Cap at 1.0
		return Math.min(score, 1.0);
	}

	/**
	 * Assess whether a focus score is reasonable for a given persona.
	 *
	 * Persona-specific ranges (examples):
	 *   - "focused-dev": 0.7-0.9 is reasonable, 0.5-0.7 is partial, <0.5 is unreasonable
	 *   - "unfocused-dev": 0.3-0.6 is reasonable, 0.15-0.3 is partial
	 *   - "productive-dev": 0.75-0.95 is reasonable
	 *
	 * For unknown personas, use conservative heuristic: 0.4-0.85 is reasonable.
	 */
	private assessFocusScoreReasonableness(
		focusScore: number,
		persona: string
	): "reasonable" | "partial" | "unreasonable" {
		const personaLower = persona.toLowerCase();

		// Persona-specific rules
		if (personaLower.includes("focused")) {
			if (focusScore >= 0.7) return "reasonable";
			if (focusScore >= 0.5) return "partial";
			return "unreasonable";
		}

		if (personaLower.includes("unfocused")) {
			if (focusScore >= 0.3 && focusScore <= 0.65) return "reasonable";
			if (focusScore >= 0.15) return "partial";
			return "unreasonable";
		}

		if (personaLower.includes("productive")) {
			if (focusScore >= 0.75) return "reasonable";
			if (focusScore >= 0.6) return "partial";
			return "unreasonable";
		}

		// Default heuristic: 0.4-0.85 is reasonable
		if (focusScore >= 0.4 && focusScore <= 0.85) return "reasonable";
		if (focusScore >= 0.2 && focusScore < 0.4) return "partial";
		if (focusScore > 0.85) return "partial";
		return "unreasonable";
	}

	/**
	 * Compare current metrics to a mock baseline.
	 *
	 * Returns a consistency score (0-1) based on:
	 *   - Work patterns ratio: baseline ±50% is acceptable, -0.3 for >50% deviation, -0.05-0.1 for minor
	 *   - Focus score diff: ±0.2 is acceptable, -0.1 for >0.1 diff, -0.2 for >0.2 diff
	 *   - Connections ratio: similar logic to work patterns (-0.2 for >50%, -0.05 for minor)
	 *
	 * Baseline 1.0 = identical outputs. Lower scores indicate divergence.
	 */
	compareToBaseline(
		current: ComparisonMetrics,
		baseline: ComparisonMetrics
	): number {
		let consistency = 1.0;

		// ── Work Patterns Consistency ───────────────────────────────
		if (baseline.workPatternsCount > 0) {
			const ratio = current.workPatternsCount / baseline.workPatternsCount;
			const deviation = Math.abs(ratio - 1.0);

			if (deviation > 0.5) {
				// >50% deviation
				consistency -= 0.3;
			} else if (deviation > 0.05) {
				// 5-50% deviation
				consistency -= 0.1;
			}
		} else if (current.workPatternsCount > 0) {
			// Baseline was 0 but current has patterns: minor penalty
			consistency -= 0.05;
		}

		// ── Focus Score Consistency ─────────────────────────────────
		const focusDiff = Math.abs(current.focusScore - baseline.focusScore);
		if (focusDiff > 0.2) {
			consistency -= 0.2;
		} else if (focusDiff > 0.1) {
			consistency -= 0.1;
		}

		// ── Connections Consistency ────────────────────────────────
		if (baseline.connectionsCount > 0) {
			const ratio = current.connectionsCount / baseline.connectionsCount;
			const deviation = Math.abs(ratio - 1.0);

			if (deviation > 0.5) {
				// >50% deviation
				consistency -= 0.2;
			} else if (deviation > 0.05) {
				// 5-50% deviation
				consistency -= 0.05;
			}
		} else if (current.connectionsCount > 0) {
			// Baseline was 0 but current has connections: very minor penalty
			consistency -= 0.02;
		}

		// Clamp to 0-1
		return Math.max(0, Math.min(1.0, consistency));
	}

	/**
	 * Generate a human-readable recommendation for this provider.
	 *
	 * Recommendations:
	 *   - Mock: "Baseline for comparison"
	 *   - Local: "Recommended for testing/dev (free, good privacy)" or similar
	 *   - Claude: "Best choice (+X% quality for $Y/day)" or null if not best
	 */
	getRecommendation(
		result: ComparisonResult,
		otherResults?: ComparisonResult[]
	): string {
		if (this.provider === "mock") {
			return "Baseline for comparison";
		}

		if (this.provider === "local") {
			return `Recommended for testing and development (free, full privacy, ${(result.metrics.responseTime / 1000).toFixed(1)}s response)`;
		}

		// Claude (anthropic) recommendation
		if (otherResults && otherResults.length > 0) {
			// Find mock baseline for comparison
			const mockBaseline = otherResults.find((r) => r.provider === "mock");
			if (mockBaseline) {
				const qualityImprovement = result.qualityScore - mockBaseline.qualityScore;
				const qualityPercent = Math.round(qualityImprovement * 100);
				const costPerYear = (result.metrics.estimatedCost * 365).toFixed(4);

				if (qualityImprovement > 0) {
					return `Best choice (+${qualityPercent}% quality for $${costPerYear}/year)`;
				} else {
					return `Similar quality to mock at $${costPerYear}/year cost`;
				}
			}
		}

		// Fallback if no comparison available
		return `Claude Haiku: $${(result.metrics.estimatedCost * 365).toFixed(4)}/year`;
	}
}
